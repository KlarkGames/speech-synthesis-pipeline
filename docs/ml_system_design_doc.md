# ML System Design Document

## Предисловие

Данный проект ведется очень сумбурно. За ~полгода работы с заказчиком я не видел ни одного ТЗ, конкретного требования. Отдельно эта проблема касается нефункциональных требований. Соответственно, некоторые вопросы, по типу скорости модели или критериев оценки качества синтеза, будут опущены, по причине отсутствия ответа со стороны заказчика.

## Содержание

- [ML System Design Document](#ml-system-design-document)
  - [Предисловие](#предисловие)
  - [Содержание](#содержание)
  - [1. Цели и предпосылки](#1-цели-и-предпосылки)
    - [1.1. Бизнес-цели](#11-бизнес-цели)
  - [2. Требования к решению](#2-требования-к-решению)
    - [2.1. Функциональные требования](#21-функциональные-требования)
    - [2.2. Нефункциональные требования](#22-нефункциональные-требования)
    - [2.3. Ограничение ответственности команды разработки](#23-ограничение-ответственности-команды-разработки)
    - [2.4. Блоксхема решения](#24-блоксхема-решения)
  - [3. Данные](#3-данные)
    - [3.1. Требования к данным](#31-требования-к-данным)
    - [3.2. Стандартизованный формат хранения данных](#32-стандартизованный-формат-хранения-данных)
    - [3.4. Источники данных](#34-источники-данных)
      - [Открытые данные](#открытые-данные)
    - [3.5. Обработка данных](#35-обработка-данных)
    - [3.6. Перечень возникавших проблем в данных](#36-перечень-возникавших-проблем-в-данных)
      - [Проблемы, при которых данные удаляются из датасетов](#проблемы-при-которых-данные-удаляются-из-датасетов)
      - [Проблемы, которые должны обрабатываться пайплайном](#проблемы-которые-должны-обрабатываться-пайплайном)
  - [4. Модели](#4-модели)
    - [4.1. Требования к модели](#41-требования-к-модели)
    - [4.2. Претенденты для использования](#42-претенденты-для-использования)
    - [4.3. Оценка результатов работы модели](#43-оценка-результатов-работы-модели)
      - [MOS (Mean Opinion Score)](#mos-mean-opinion-score)
      - [DNSMOS (Deep Noise Suppression Mean Opinion Score)](#dnsmos-deep-noise-suppression-mean-opinion-score)
      - [NISQA (Speech Quality and Naturalness Assessment)](#nisqa-speech-quality-and-naturalness-assessment)
  - [5. Деплой](#5-деплой)
  - [6. Тестирование](#6-тестирование)
  - [7. Критерии успешного завершения проекта](#7-критерии-успешного-завершения-проекта)


## 1. Цели и предпосылки

### 1.1. Бизнес-цели

**Бизнес-цель** - продемонстрировать современность имеющихся в компании технологий и подходов перед заказчиком. Актуализировать технологии. 

Разрабатываемая командой часть проекта является **Emotional Speech Synthesis (Дальше ESS)** модель для озвучки сгенерированных LLM диалогов. Озвучка ожидается "на лету", т.е. нет возможности озвучить диалоги заранее.

У разрабатывающей команды есть наработки в области ESS, данный проект позволит актуализировать имеющиеся подходы и технологии. 

Успешным результатом **с точки зрения заказчика** является разворачиваемая на инфраструктуре заказчика и силами его разработчиков ESS модель. Качество модели должно субъективно удовлетворять представителей заказчика.

Успешным результатом **c точки зрения разрабатывающей команды** является отданный заказчику checkpoint модели и GitLab репозиторий с инструкциями по запуску. Дополнительно упомянутые выше артефакты должны удовлетворять всем оговоренным функциональным и нефункциональным требованиям.

## 2. Требования к решению

### 2.1. Функциональные требования

1. Пользователь должен при имеющихся тексте и идентификаторах голоса и эмоции получить озвучку текста с соответствующими голосом и эмоцией.
2. Пользователь может вместо идентификатора голоса и эмоции дать на вход аудиофайл, содержащий пример требуемого голоса и эмоции. 
3. Команда разработки со стороны заказчика должна иметь возможность запустить Docker контейнер с моделью и чекпоинтом и повторить действия из пункта 1.

### 2.2. Нефункциональные требования

1. На инфраструктуре команды разработчиков разрабатываемый контейнер с моделью должен держать 100 RPS.
2. Заказчик самостоятельно заботится о масштабируемости и доступности поставляемого контейнера в своей инфраструктуре.
3. Текст должен быть представлен без дополнительных тегов (По типу Markdown, HTML), на английском языке в нижнем и верхнем регистре с числами и символами препинания входящими в список **!?.,"'()-`+**
4. Идентификаторы голоса и эмоции ожидаются в виде текстовой строки в нижнем регистре с символами английского алфавита и числами. При отсутствии требуемой эмоции или голоса - контейнер должен вернуть ошибку с перечнем имеющихся эмоций и голосов. 
5. Пример аудио с голосом и эмоцией ожидается с частотой дискретизации 44.1 kHZ с 1 каналом (mono) и Encoding'ом 16-bit Signed Integer PCM.
6. Если входные данные не соответствуют пунктам 2-4, несоответствия должны обрабатываться в контейнере модели. 
7. Возвращаемое аудио так же должно соответствовать пункту 4.
8. Качество синтезируемого аудио должно удовлетворять сторону заказчика. 
9. Синтезируемое аудио должно быть без заметных артефактов, по типу скрежета, писка, робовойса, белого шума.

### 2.3. Ограничение ответственности команды разработки

Команда разработки предоставляет Docker контейнер с моделью и чекпоинты для запуска. Команда разработки вносит изменения в контейнер, если они не удовлетворяют требованиям. Однако команда разработки не отвечает за интеграцию этого контейнера в конечный продукт заказчика. 

Команда разработки может настоять на проведение Mean Opinion Score теста (MOS) для объективной оценки качества синтеза голоса в случаях разногласий в субъективной оценки результатов. 

Команда разработки не предоставляет заказчику информацию о дополнительных данных, используемых для обучения, и о методах/пайплайнах обработки и обучения.

### 2.4. Блоксхема решения

![alt text](<images/Model Workflow.drawio.png>)

## 3. Данные

### 3.1. Требования к данным

Данные должны удовлетворять следующему:
- Данные представлены парой аудиофайл - текстовый файл. В аудиофайле содержится голос, произносящий текст, хранящийся в текстовом файле. 
- Качество голоса на аудио должно соответствовать тому, которое ожидается в качестве синтезируемого от модели.
- Датасет должен иметь однозначную индикацию, к какому спикеру пренадлежит голос на аудиофайлах. 
- Аудиофайлы должны иметь частоту дискретизации не менее 16kHZ
- Допускается использование разной канальности и методов кодирования. Рекомендуется использовать аудио с 1 каналом (mono) и Encoding'ом 16-bit Signed Integer PCM.
- Текст должен быть представлен без дополнительных тегов (По типу Markdown, HTML), на английском языке в нижнем и верхнем регистре с числами и символами препинания входящими в список **.,'`**. Другие символы будут удалены или заменены на их аналоги (Например ! -> .)
- Знаки препинания должны быть раставлены в местах, где присутствует характерная пауза. Точка - длинная пауза (>0.3с), запятая - которкая (>0.15с).

### 3.2. Стандартизованный формат хранения данных

Все данные должны быть приведены к одному формату, представленному ниже:

```
all_datasets/                # Главная папка с несколькими мультиспикерными датасетами
│
├── metadata.csv             # Главная метадата, содержащая пути ко ВСЕМ wav файлам в текущем датасете
│
├── EmoV_DB/                 # Папка мультиспикерного датасета EmoV_DB
|   ├── metadata.csv         # Метадата содержащая пути ко всем файлам внутри датасета EmoV_DB
│   ├── speaker_1/           # Папка спикера
│   │   └── wavs/            # Папка с аудиофайлами или их подкатегориями
│   │       ├── file1.wav
│   │       └── ...
│   ├── speaker_2/
│   |   └── wavs/
│   |       ├── subfolder/   # Подпапка с аудиофайлами, например, по книгам (опционально - если есть такое разделение)
│   |       |   ├── file3.wav
│   |       |   └── ...
|   |       ├── file11.wav
|   |       └── ...
|   ├── ...
|   └── wavs                 # Папка с аудиофайлами без спикеров
|       ├── no_speaker1.wav
|       └── ...
|
└── MLS/                     # Папка мультиспикерного датасета MLS
    ├── metadata.csv
    ├── speaker_1/
    │   └── wavs/
    │       ├── file1.wav
    |       └── ...
    ├── speaker_2/
    |   └── wavs/
    |       ├── file2.wav
    |       └── ...
    └── wavs                   # Папка с аудиофайлами без спикеров
        ├── no_speaker1.wav
        └── ...
```

Файл metadata.csv должен соответствовать следующей структуре (all_datasets/EmoV_DB/metadata.csv):

| path_to_wav                        | speaker_id | text                   |
| ---------------------------------- | ---------- | ---------------------- |
| speaker_1/wavs/file1.wav           | 0          | Hello world            |
| speaker_2/wavs/subfolder/file3.wav | 1          | It's me, Mario         |
| speaker_2/wavs/file11.wav          | 1          | Mario time!            |
| wavs/no_speaker1.wav               | -1         | Keep you waiting, huh? |

**Для аудио с отсутствующей информацией о спикере проставляется ID -1.**

*Speaker_id* и *path_to_wav* являются локальными в пределах датасета. Пример для сравнения (all_datasets/metadata.csv)

| path_to_wav                                | speaker_id | text                   |
| ------------------------------------------ | ---------- | ---------------------- |
| EmoV_DB/speaker_1/wavs/file1.wav           | 0          | Hello world            |
| EmoV_DB/speaker_2/wavs/subfolder/file3.wav | 1          | It's me, Mario         |
| EmoV_DB/speaker_2/wavs/file11.wav          | 1          | Mario time!            |
| EmoV_DB/wavs/no_speaker1.wav               | -1         | Keep you waiting, huh? |
| MLS/speaker_1/wavs/file1.wav               | 2          | Nanomachines, son!     |
| MLS/speaker_2/wavs/file2.wav               | 3          | Leeroooooy Jenkins!    |
| MLS/wavs/no_speaker1.wav                   | -1         | Very dramatic, Uther.  |

Так же стоит учитывать следующие замечания:
- Аудио файлы **должны быть** в формате .wav.
- Аудио файлы **должны быть** в локальной wavs директории.
- Подразумевается что **нет несоответствий** между информацией в metadata.csv и соответствующей структуре директорий.
- Аудиофайлы **должны быть** одного sample rate
- Аудиофайлы **представлены с 1 каналом (mono).**
- .csv файлы **должны быть** сохранены с параметрами **sep='|', index=False**
- Колонки для .csv файлов **должны быть** в порядке *path_to_wav | text | speaker_id* для поддержания обратной совместимости

### 3.4. Источники данных

*Большая часть данных скрыта из-за NDA*

#### Открытые данные

- Multilingual LibriSpeech - Большой датасет с записями аудиокниг с соответствующим текстом. Размечен по спикерам, имеет 44 тысяч часов записи, равномерно распределенной между мужскими и женскими голосами.
- EmoV_DB - Небольшой датасет с записями актеров, которые зачитывают текст в заданной эмоции.  

Подробнее о датасетах и их форматах можно посмотреть в [datasets.md](datasets.md)

### 3.5. Обработка данных

Данные обрабатываются в следующем порядке:
- Все датасеты приводятся к [стандартизированному формату](#32-стандартизованный-формат-хранения-данных).
- Датасеты, для которых качество аудио субъективно неудовлетворительное, обрабатываются с помощью Resemble-Enhancer'а. Данный инструмент используется для восстановление качества голоса с старых записей.
- Датасеты проходят фильтрацию с помощью Automatic Speech Recognition модели. Если WER и CER между распознанными и размеченными текстами превышают заданные пороги - данные семплы удаляются из датасета. (Удаляются не все файлы, а только информация о них в главном metadata.csv файле)
- Датасеты проходят восстановление пунктуации в местах, где на аудио присутствуют паузы с помощью Montreal Forced Aligner. Данный инструмент по заданному тексту и аудиофайлу получает информацию о промежутках времени, когда произносятся соответствующие слова.
- Датасеты вручную валидируются на отсутствие явных ошибок.
- Датасеты объединяются в один большой датасет с общим файлом metadata.csv и уникальными на уровне всех данных ID спикеров.  

### 3.6. Перечень возникавших проблем в данных

#### Проблемы, при которых данные удаляются из датасетов
- Несоответствие текста в аудио и в тексте. 
- Очень шумные записи. 
- Неразборчивые произношения слов.  

#### Проблемы, которые должны обрабатываться пайплайном
- Отличная от 44.1kHZ частота дескретизации данных.
- Разное количество каналов записи. Приводится к 1-каналу (mono)
- Разная кодировка аудио. Приводится к 16-bit Signed Integer PCM.
- Слишком длинные аудио. Делятся на 20 секундные куски.
- Слишком мало записей конкретного голоса. Не обрабатывается.
- Слишком много записей конкретного голоса. Обрезается до общей длительности в 1 час. 

## 4. Модели

### 4.1. Требования к модели

- Входные и выходные данные должны соответствовать требованиям, представленным в [пункте 3.1](#31-требования-к-данным) критериям.
- На данной стадии проекта нет ограничений на размер модели по памяти и количеству параметров.
- Модель должна генерировать записи с Real Time Factor (RTF) не выше 0.2. (Что означает, что за 1 секунду работы будет сгенерировано не менее 5 секунд речи.)

### 4.2. Претенденты для использования

*Естественно модель, которую мы сейчас используем под NDA, но ниже есть несколько открытых моделей в качестве аналогов.*

- [MeloTTS](https://github.com/myshell-ai/MeloTTS)
- [Bert-VITS2](https://github.com/fishaudio/Bert-VITS2)
- [VITS2](https://github.com/daniilrobnikov/vits2)

### 4.3. Оценка результатов работы модели

#### MOS (Mean Opinion Score)

Данная метрика берет свое начало с статьи [P.800 : Methods for subjective determination of transmission quality от ITU](https://openreview.net/pdf?id=bnVBXj-mOc), где авторы предлагают методы оценки субъективных показателей качества звука. Изначально данные рекомендации разрабатывались для сферы телефонии. 

Основная идея заключается в следующем. Берется выборка пользователей. Каждому человеку предлагается прослушать аудио и его качество от 0 до 5 по трем критериям. При этом каждому числу соответствует расшифровка. Подробные таблицы представлены ниже:

- **Listening-quality scale**
  
| Quality of the speech | Score |
| --------------------- | ----- |
| Excellent             | 5     |
| Good                  | 4     |
| Fair                  | 3     |
| Poor                  | 2     |
| Bad                   | 1     |

- **Listening-effort scale**
  
> The heading of the listening-effort opinion scale is particularly important. Without it, the other descriptions are liable to be seriously misunderstood.

| Effort required to understand the meanings of sentences | Score |
| ------------------------------------------------------- | ----- |
| Complete relaxation possible; no effort required        | 5     |
| Attention necessary; no appreciable effort required     | 4     |
| Moderate effort required                                | 3     |
| Considerable effort required                            | 2     |
| No meaning understood with any feasible effort          | 1     |

- **Loudness-preference scale**
  
| Loudness preference         | Score |
| --------------------------- | ----- |
| Much louder than preferred  | 5     |
| Louder than preferred       | 4     |
| Preferred                   | 3     |
| Quieter than preferred      | 2     |
| Much quieter than preferred | 1     |


Исходя из описанных в статье [Stuck in the MOS pit: A critical analysis of MOS test methodology in TTS evaluation](https://openreview.net/pdf?id=bnVBXj-mOc) замечаний следует обратить внимание на следующие особенности измерения данной метрики:

1. Получаемые оценки **напрямую зависят** от формулировки вопроса и представленных вариантов ответа. Варианты "Very Bad - Very Good" и "Bad - Excillent" будут иметь различное распределение на одних и тех же выборках людей и аудио. 
2. **Нельзя** напрямую сравнивать полученные результаты спустя длительное время. Это связанно с тем, что человек имеет склонность использовать весь диапазон измеряемой шкалы. Соответственно, может случиться парадоксальная ситуация, когда качество аудио улучшилось, а показатели в их абсолютном значении не изменились.
**На примере:** Есть аудио объективного качества 1, 3, 7, 10. Есть субъективная шкала от 1 до 5. Если дать человеку разметить выборку 1-3-7-10, то полученная оценка будет примерно следующей; 1-2-4-5. Если дать на оценку 3-7-10, то оценки будут: 1-3-5. Парадокс: качество выборки улучшилось, а показатели остались прежними.
**Предлагаемое решение:** стоит добавлять в выборку результаты из прошлых итераций. Таким образом, сохраняя прошлые показатели можно точно быть уверены, что нынешние лучше/хуже по сравнению с ними.
3. Желательно иметь информацию о людях, входящих в группу оценки. Например для английского языка хотелось бы знать, откуда родом оценщики и каким диалектом английского они владеют. 

#### DNSMOS (Deep Noise Suppression Mean Opinion Score)

Данная метрика представлена в статье DNSMOS P.835: A Non-Intrusive Perceptual Objective Speech Quality Metric to Evaluate Noise Suppressors. Она предлагает натренировать CNN для оценки показателей MOS. Модель небольшая, структура представлена ниже:

| Layer                          | Output dimension      |
| ------------------------------ | --------------------- |
| Input                          | 900 x 120 x 1         |
| Conv: 128, (3 x 3), ‘ReLU’     | 900 x 161 x 128       |
| Conv: 64, (3 x 3), ‘ReLU’      | 900 x 161 x 64        |
| Conv: 64, (3 x 3), ‘ReLU’      | 900 x 161 x 64        |
| Conv: 32, (3 x 3), ‘ReLU’      | 900 x 161 x 32        |
| MaxPool: (2 x 2), Dropout(0.3) | 450 x 80 x 32         |
| Conv: 32, (3 x 3), ‘ReLU’      | 450 x 80 x 32         |
| MaxPool: (2 x 2), Dropout(0.3) | 225 x 40 x 32         |
| Conv: 32, (3 x 3), ‘ReLU’      | 112 x 20 x 32         |
| MaxPool: (2 x 2), Dropout(0.3) | 112 x 15 x 32         |
| Conv: 64, (3 x 3), ‘ReLU’      | 112 x 20 x 64         |
| GlobalMaxPool                  | 1 x 64                |
| Dense: 128, ‘ReLU’             | 1 x 128               |
| Dense: 64, ‘ReLU’              | 1 x 64                |
| Dense:                         | 1 or 3	1 x 1 or 1 x 3 |

>The input to the model is log power spectrogram with a 320 FFT size computed over a clip of length 9 seconds sampled at 16 kHz with a frame size of 20 ms and hop length of 10 ms. This results in an input dimension of 900 x 161.   


После того, как были собранно достаточное количество оценок MOS по нашим аудио можно натренировать простой предсказатель этих метрик. Вижу использование в двух ситуациях: отслеживание качества на инференсе модели и прогнозирование результатов обучения без обращения к стороне оценки. При сборе данных должен учитываться пункт №2 из комментариев к MOS.

#### NISQA (Speech Quality and Naturalness Assessment)

Данная модель является еще одним способом по собранным данным MOS научить модель-предсказатель. 

Полезные ссылки:

Доклад на Data Fest 2024: [NISQA-S: Оценка качества для потокового аудио (Team VK)](https://youtu.be/PvZuTUnZa2Q?t=23111)
Оригинальный репозиторий: https://github.com/gabrielmittag/NISQA
Усовершенствованный репозиторий от команды VK: https://github.com/deepvk/NISQA-s

## 5. Деплой

Результат работы отправляется заказчику в следующем виде:

1. Поставляются 2 контейнера: FastAPI сервер-обертка и Triton Inference сервер с моделью.
2. FastAPI сервер реализует в себе обработку проверки и обработки входных и выходных данных.
3. FastAPI сервер обрабатывает ошибки и сообщает о них пользователю. Ожидаемые ошибки: отсутствие памяти на GPU; некорректные входные данные; отсутствие доступа к Triton Inference серверу.  
4. Triton Inference Server реализует в себе запуск модели, масштабирование модели на нескольких GPU, если требуется.
5. Мониторинг загруженности осуществляется через соответствующий порт в Triton Inference Server. Заказчик реализует эту логику самостоятельно.

## 6. Тестирование

Тестирование системы должно удовлетворять следующим критериям:

1. Присутствует End-to-End тест, покрывающий всю возможную логику взаимодействия с системой, а именно: штатная работа системы с корректными данными; работа системы с некорректными данными; работа системы с отсутствующими данными; работа системы с отсутствующими компонентами системы (Triton Inference Server)
2. Покрытие unit-тестами FastAPI сервиса должно составлять не менее 70%.
3. Проведено нагрузочное тестирование работы системы. Проверено, что оно удовлетворяет критериям из [пункта 2.2. Нефункциональные требования](#22-нефункциональные-требования) и [пункта 4.1. Требования к модели](#41-требования-к-модели).

## 7. Критерии успешного завершения проекта

1. Поставляемая система запущена на стороне заказчика без критических проблем и соответствует заявленным функциональным и нефункциональным требованиям.
2. Качество синтезируемого голоса соответствует качеству, на котором сошлись обе стороны после этапа обучения модели.
3. В случае несоответствия мнений по пункту 2 команда разработки может настоять на проведении Mean Opinion Score тестирования на выборке из не менее 15 человек при прослушивании каждым 20 семплов генерации с перекрестной оценкой троих человек на один семпл. Модели считаются идентичными при p-value > 0.05 при проведении A/B теста с точностью 95%.